{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "from run_logistic_simulations import *\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_SEED = 58\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doses = [0.5, 1, 3, 5, 6] # From figure 6 and in units (mg/m^2 per day)\n",
    "doses = [2.9444390, -2.1972246, -1.7346011, -0.7081851,  0.0000000] # From figure 6 and in units (mg/m^2 per day)\n",
    "true_toxic_prob_s1 = (0.25, 0.3, 0.5, 0.6, 0.7) # Given by assignment instructions, scenario 1\n",
    "true_toxic_prob_s2 = (0.01, 0.05, 0.2, 0.3, 0.5) # Given by assignment instructions, scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "p_i = np.array([0.05, 0.10, 0.15, 0.33, 0.50])\n",
    "# doses_transformed = (np.log(p_i / (1 - p_i)) - 3) / np.exp(1) \n",
    "doses_transformed = [0.5, 1, 3, 5, 6]\n",
    "doses_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "with pm.Model() as logistic_regression_model:\n",
    "    x = pm.ConstantData(\"doses\", doses_transformed, dims=\"observation\")\n",
    "    # priors\n",
    "    beta0 = pm.Normal(\"beta0\", mu=-3, sigma=1) # Made up by myself\n",
    "    beta1 = pm.Exponential(\"beta1\", lam=2) # given from the paper\n",
    "    # linear model\n",
    "    mu = beta0 + beta1 * x\n",
    "    p = pm.Deterministic(\"p\", sigmoid(mu), dims=\"observation\")\n",
    "    # likelihood\n",
    "    y_obs = pm.Bernoulli(\"y\", logit_p=mu, observed=[0,0,0,0,0], dims=\"observation\")\n",
    "    # pm.Logistic(\"y\", mu=mu, observed=data['toxicity_event'], dims=\"observation\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_regression_model:\n",
    "    idata = pm.sample_prior_predictive(samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sigmoid function\n",
    "def sigmoid(x, beta0, beta1):\n",
    "    return 1 / (1 + np.exp(-(beta0 + beta1 * x )))\n",
    "\n",
    "# Extract betas from the trace\n",
    "beta0 = np.mean(idata.prior['beta0'].values)\n",
    "beta1 = np.mean(idata.prior['beta1'].values)\n",
    "\n",
    "# Generate x values\n",
    "x_values = np.array([0.5, 1, 3, 5, 6])\n",
    "\n",
    "# Generate y values (sigmoid probabilities)\n",
    "y_values = sigmoid(x_values, beta0, beta1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_values, y_values, label='Sigmoid curve', marker='o')\n",
    "plt.xlabel('Doses')\n",
    "plt.ylabel('Probability of Toxicity Event')\n",
    "plt.title(\"prior predictive check\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_observation = np.random.binomial(1, p=true_toxic_prob_s1[0], size=3) # first cohort, first dose\n",
    "doses_observed = np.ones(3) * doses[0] # doses given to the three participants\n",
    "data = pd.DataFrame({'doses':doses_observed, 'toxicity_event': toxicity_observation})\n",
    "coords = {\"observation\": data.index.values}\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# with pm.Model(coords=coords) as logistic_regression_model:\n",
    "#     x = pm.ConstantData(\"doses\", data['doses'], dims=\"observation\")\n",
    "#     # priors\n",
    "#     beta0 = pm.Normal(\"beta0\",mu=-1, sigma=2) # Made up by myself\n",
    "#     beta1 = pm.Exponential(\"beta1\", lam=1) # given from the paper\n",
    "#     # linear model\n",
    "#     mu = beta0 + beta1 * x\n",
    "#     p = pm.Deterministic(\"p\", sigmoid(mu), dims=\"observation\")\n",
    "#     # likelihood\n",
    "#     y_obs = pm.Bernoulli(\"y\", logit_p=mu, observed=data['toxicity_event'], dims=\"observation\")\n",
    "#     # pm.Logistic(\"y\", mu=mu, observed=data['toxicity_event'], dims=\"observation\")\n",
    "    \n",
    "with pm.Model(coords=coords) as logistic_regression_model:\n",
    "    x = pm.ConstantData(\"doses\", data['doses'], dims=\"observation\")\n",
    "    # priors\n",
    "    beta0 = pm.Normal(\"beta0\",mu=0, sigma=2) # Made up by myself\n",
    "    beta1 = pm.Exponential(\"beta1\", lam=1) # given from the paper\n",
    "    # linear model\n",
    "    mu = beta0 + beta1 * x\n",
    "    p = pm.Deterministic(\"p\", sigmoid(mu), dims=\"observation\")\n",
    "    # likelihood\n",
    "    y_obs = pm.Bernoulli(\"y\", logit_p=mu, observed=data['toxicity_event'], dims=\"observation\")\n",
    "    # pm.Logistic(\"y\", mu=mu, observed=data['toxicity_event'], dims=\"observation\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_regression_model:\n",
    "    idata = pm.sample_prior_predictive(samples=3000, random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sigmoid function\n",
    "def sigmoid(x, beta0, beta1):\n",
    "    return 1 / (1 + np.exp(-(beta0 + beta1 * x )))\n",
    "\n",
    "# Extract betas from the trace\n",
    "beta0 = np.mean(idata.prior['beta0'].values)\n",
    "beta1 = np.mean(idata.prior['beta1'].values)\n",
    "\n",
    "# Generate x values\n",
    "x_values = np.linspace(0, max(doses), num=1000)\n",
    "\n",
    "# Generate y values (sigmoid probabilities)\n",
    "y_values = sigmoid(x_values, beta0, beta1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_values, y_values, label='Sigmoid curve')\n",
    "# plt.scatter(data['doses'], data['toxicity_event'], color='red', label='Data')\n",
    "plt.xlabel('Doses')\n",
    "plt.ylabel('Probability of Toxicity Event')\n",
    "plt.title(\"prior predictive check\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data(relevant_index):\n",
    "    \"\"\" Simulates whether any of the 3 participants have a toxicity event given by the unknown probabilities.\n",
    "\n",
    "    Args:\n",
    "        relevant_index (Int): The index associated with the dose being used on the three samples.\n",
    "\n",
    "    Returns:\n",
    "        Pandas Dataframe: Contains the doses the three participants took and whether each participant had a toxicity event\n",
    "    \"\"\"\n",
    "    toxicity_observation = np.random.binomial(1, p=true_toxic_prob_s1[relevant_index], size=3) # 3 samples per cohort\n",
    "    doses_observed = np.ones(3) * doses[relevant_index] # doses given to the three participants\n",
    "    # store data in a dataframe that will later be concatenated to make one dataframe\n",
    "    data = pd.DataFrame({'doses':doses_observed, 'toxicity_event': toxicity_observation})\n",
    "    return data\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def run_model(data):\n",
    "    \"\"\" Creates a logistic regression model using the priors given in the paper\n",
    "    and the data collected up until this point. \n",
    "\n",
    "    Args:\n",
    "        data (Pandas Dataframe): Same dataframe given by sim_data()\n",
    "\n",
    "    Returns:\n",
    "        pymc model: Fitted model based on priors and the current data collected\n",
    "    \"\"\"\n",
    "    coords = {\"observation\": data.index.values} \n",
    "    with pm.Model(coords=coords) as logistic_regression_model:\n",
    "        x = pm.ConstantData(\"doses\", data['doses'].values, dims=\"observation\")\n",
    "        # priors\n",
    "        beta0 = pm.Normal(\"beta0\", mu=-3, sigma=2) # Made up by myself\n",
    "        beta1 = pm.Exponential(\"beta1\", lam=1) # given from the paper\n",
    "        # linear model\n",
    "        mu = beta0 + beta1 * x\n",
    "        # probabilities\n",
    "        p = pm.Deterministic(\"p\", sigmoid(mu), dims=\"observation\")\n",
    "        # likelihood\n",
    "        y_obs = pm.Bernoulli(\"y\", logit_p=mu, observed=data['toxicity_event'].values, dims=\"observation\") \n",
    "    return logistic_regression_model\n",
    "    \n",
    "    \n",
    "def get_next_dose(idata):\n",
    "    # Extract betas from the trace\n",
    "    beta0 = np.mean(idata.posterior['beta0'].values)\n",
    "    beta1 = np.mean(idata.posterior['beta1'].values)\n",
    "    # store the doses in a numpy array\n",
    "    x_values = np.array(doses)\n",
    "    # Generate y values (sigmoid probabilities)\n",
    "    y_values = sigmoid(beta0 + beta1 * x_values)\n",
    "    # select the highest dose that falls under the MTD threshold (0.33)\n",
    "    # if the lowest dose is predicted to be above the threshold, return the next dose INDEX equal to 0 which is a dose of 0.5\n",
    "    if len(y_values[y_values <= 0.33]) == 0:\n",
    "        next_dose = 0\n",
    "    else:\n",
    "        next_dose = np.argmax(y_values[y_values <= 0.33])\n",
    "    return next_dose\n",
    "\n",
    "\n",
    "def run_single_trial():\n",
    "    \"\"\" The setup is as follows:\n",
    "    1. Choose a starting dose to test on the first three patients. \n",
    "    2. Simulate whether each patient has a toxicity event with sim_data().\n",
    "    3. run the model with the data collected so far. \n",
    "    4. Using the posterior estimates of the beta's, predict the highest dose that has a predicted probability of toxicity below 0.33.\n",
    "    5. Repeat steps 2-4 until all 36 patients have been tested.\n",
    "    \n",
    "    numpyro appears to be a faster engine and is able to run the model in a reasonable amount of time. There are other options \n",
    "    such as variational inference or even quadratic approximation. However, I am not familiar with these methods.\n",
    "    \"\"\"\n",
    "    # first run of the model with a starting dose of 1 (index of 1)\n",
    "    data = sim_data(0) \n",
    "    logistic_regression_model = run_model(data)\n",
    "    with logistic_regression_model:\n",
    "        # idata = pm.sample(500, tune=200, chains=2, random_seed=rng, cores=4, progressbar=False, nuts_sampler='numpyro')\n",
    "        idata = pm.sampling.jax.sample_numpyro_nuts(800, 200, cores=5, target_accept=0.65, progressbar=False)\n",
    "    next_dose = get_next_dose(idata)\n",
    "    \n",
    "    # We already went through 3 samples out of 36. 36 // 3 = 12 - 1 = 11\n",
    "    for remaining_trials in range(11):\n",
    "        new_data = sim_data(next_dose)\n",
    "        # combine the data collected previously with the new simulated data\n",
    "        data = pd.concat([data, new_data], axis=0, ignore_index=True)\n",
    "        # run the model on all the data collected so far\n",
    "        logistic_regression_model = run_model(data)\n",
    "        with logistic_regression_model:\n",
    "            idata = pm.sampling.jax.sample_numpyro_nuts(800, 200, cores=5, target_accept=0.65, progressbar=False)\n",
    "            # idata = pm.sample(500, tune=200, chains=2, random_seed=rng, cores=4, progressbar=False, nuts_sampler='numpyro')\n",
    "        next_dose = get_next_dose(idata)\n",
    "    \n",
    "    beta0 = np.mean(idata.posterior['beta0'].values)\n",
    "    beta1 = np.mean(idata.posterior['beta1'].values)\n",
    "    # store the doses in a numpy array\n",
    "    x_values = np.array(doses)\n",
    "    # Generate y values (sigmoid probabilities)\n",
    "    y_values = sigmoid(beta0 + beta1 * x_values)\n",
    "    \n",
    "    return data, y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = []\n",
    "sigmoid_probabilities = []\n",
    "# we should have 1000 simulations but using 350 for now\n",
    "for sim in tqdm(range(350)):\n",
    "    data, trial_probabilities = run_single_trial()\n",
    "    total_data.append(data)    \n",
    "    sigmoid_probabilities.append(trial_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"state.bin\", \"wb\") as f: # \"wb\" because we want to write in binary mode\n",
    "#     pickle.dump(total_data, f)\n",
    "    \n",
    "# with open(\"state.bin\", \"rb\") as f: # \"rb\" because we want to read in binary mode\n",
    "#     total_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"sigmoid_probs_pt4.pkl\", \"wb\") as f: # \"wb\" because we want to write in binary mode\n",
    "    pickle.dump(sigmoid_probabilities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(total_data)):\n",
    "    # add a column that tracks which simulation run is associated with each row\n",
    "    total_data[i]['sim_run'] = i\n",
    "    \n",
    "# combine list of dataframes to one dataframe\n",
    "total_data = pd.concat(total_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.to_parquet('finished_simulations_pt4.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['doses'][::3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_parquet('finished_simulations.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['doses'][::3].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract betas from the trace\n",
    "beta0 = np.mean(idata.posterior['beta0'].values)\n",
    "beta1 = np.mean(idata.posterior['beta1'].values)\n",
    "\n",
    "# Define a sigmoid function\n",
    "def sigmoid(x, beta0, beta1):\n",
    "    return 1 / (1 + np.exp(-(beta0 + beta1* x )))\n",
    "\n",
    "# Generate x values\n",
    "x_values = np.linspace(0, max(doses), num=1000)\n",
    "\n",
    "# Generate y values (sigmoid probabilities)\n",
    "y_values = sigmoid(x_values, beta0, beta1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_values, y_values, label='Sigmoid curve')\n",
    "plt.scatter(data['doses'], data['toxicity_event'], color='red', label='Data')\n",
    "plt.scatter(doses, true_toxic_prob_s1, color='black', label='True Probabilities')\n",
    "plt.xlabel('Doses')\n",
    "plt.ylabel('Probability of Toxicity Event')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "60\\%\n",
    "\n",
    "and 45\\%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_dose(sigmoid_probs):\n",
    "    selected_doses = []\n",
    "    for probs_list in sigmoid_probs:\n",
    "        if len(probs_list[probs_list <= 0.33]) == 0:\n",
    "            selected_doses.append(0)\n",
    "        else:\n",
    "            selected_doses.append(np.argmax(probs_list[probs_list <= 0.33]))\n",
    "    return np.array(selected_doses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"gabe_sim_files/S2_finished_simulations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gabe_sim_files/S2_sigmoid_probs.pkl\", \"rb\") as f: # \"rb\" because we want to read in binary mode\n",
    "    S2_sigmoid_probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_sigmoid_probs = np.array(S2_sigmoid_probs)\n",
    "selected_doses = get_selected_dose(S2_sigmoid_probs)\n",
    "S2_count_series = pd.Series({dose: np.sum(selected_doses == dose) for dose in [0, 1, 2, 3, 4]})\n",
    "S2_count_series / S2_count_series.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gabe_sim_files/sigmoid_probs_pt3.pkl\", \"rb\") as f: # \"rb\" because we want to read in binary mode\n",
    "    sigmoid_probs_pt3 = pickle.load(f)\n",
    "with open(\"gabe_sim_files/sigmoid_probs_pt4.pkl\", \"rb\") as f: # \"rb\" because we want to read in binary mode\n",
    "    sigmoid_probs_pt4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_sigmoid_probs = np.concatenate((np.array(sigmoid_probs_pt3), np.array(sigmoid_probs_pt4)))\n",
    "selected_doses = get_selected_dose(S1_sigmoid_probs)\n",
    "S1_count_series = pd.Series({dose: np.sum(selected_doses == dose) for dose in [0, 1, 2, 3, 4]})\n",
    "S1_count_series.index = doses\n",
    "S1_count_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([(y_val <= 0.33)[0].any() for y_val in S1_sigmoid_probs]) / len(S1_sigmoid_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_count_series / S1_count_series.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
