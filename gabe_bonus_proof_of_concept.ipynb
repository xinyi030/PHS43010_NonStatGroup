{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from run_logistic_simulations import sim_data\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_toxic_prob_s1 = (0.25, 0.3, 0.5, 0.6, 0.7) # Given by assignment instructions, scenario 1\n",
    "true_toxic_prob_s2 = (0.01, 0.05, 0.2, 0.3, 0.5) # Given by assignment instructions, scenario 2\n",
    "doses = np.array([0.5, 1, 3, 5, 6]) # From figure 6 and in units (mg/m^2 per day)\n",
    "num_sims=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(true_toxic_probabilities, num_sims=1000):\n",
    "    results = []\n",
    "    final_model = []\n",
    "    for sim_run in tqdm(range(num_sims)):\n",
    "        data = sim_data(0, true_toxic_probabilities)\n",
    "        X = data['doses'].values.reshape(-1, 1) # only one feature so needs to be reshaped to a column vector\n",
    "        y = data['toxicity_event']\n",
    "        only_one_class_bool = (y == 0).sum() == len(y)\n",
    "        if only_one_class_bool:\n",
    "            next_dose_idx = 4\n",
    "        elif (y == 1).sum() == len(y):\n",
    "            next_dose_idx = 0\n",
    "        else:\n",
    "            clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "            predicted_prob_toxic = clf.predict_proba(doses.reshape(-1, 1))[:, 1]\n",
    "            next_dose_idx = np.argmin(np.abs(predicted_prob_toxic - 0.33))\n",
    "\n",
    "        for sample in range(11):\n",
    "            new_data = sim_data(next_dose_idx, true_toxic_probabilities)\n",
    "            data = pd.concat([data, new_data], axis=0, ignore_index=True)\n",
    "            X = data['doses'].values.reshape(-1, 1) # only one feature so needs to be reshaped to a column vector\n",
    "            y = data['toxicity_event']\n",
    "            only_one_class_bool = (y == 0).sum() == len(y)\n",
    "            if only_one_class_bool:\n",
    "                next_dose_idx = 4\n",
    "            elif (y == 1).sum() == len(y):\n",
    "                next_dose_idx = 0\n",
    "            else:\n",
    "                clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "                predicted_prob_toxic = clf.predict_proba(doses.reshape(-1, 1))[:, 1]\n",
    "                next_dose_idx = np.argmin(np.abs(predicted_prob_toxic - 0.33))\n",
    "        results.append(next_dose_idx)\n",
    "        final_model.append(clf)\n",
    "    true_label_idx = np.argmin(np.abs(np.array(true_toxic_probabilities) - 0.33))\n",
    "    return results, true_label_idx, final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, true_label_idx, final_model_s1 = run_simulation(true_toxic_prob_s1, num_sims=num_sims)\n",
    "_, counts = np.unique(results, return_counts=True)\n",
    "percent_class_predictions = counts / sum(counts)\n",
    "percent_class_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy for scenario 1: {percent_class_predictions[true_label_idx]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, true_label_idx, final_model_s2 = run_simulation(true_toxic_prob_s2, num_sims=num_sims)\n",
    "_, counts = np.unique(results, return_counts=True)\n",
    "percent_class_predictions = counts / sum(counts)\n",
    "percent_class_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy for scenario 2: {percent_class_predictions[true_label_idx]}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we try the revised approach where we reweight the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_toxic_probabilities = true_toxic_prob_s1\n",
    "\n",
    "results = []\n",
    "final_model = []\n",
    "for sim_run in tqdm(range(num_sims)):\n",
    "    data = sim_data(0, true_toxic_probabilities)\n",
    "    X = data['doses'].values.reshape(-1, 1) # only one feature so needs to be reshaped to a column vector\n",
    "    y = data['toxicity_event']\n",
    "    only_one_class_bool = (y == 0).sum() == len(y)\n",
    "    if only_one_class_bool:\n",
    "        next_dose_idx = 4\n",
    "    elif (y == 1).sum() == len(y):\n",
    "        next_dose_idx = 0\n",
    "    else:\n",
    "        clf = LogisticRegression(solver='lbfgs',random_state=0).fit(X, y)\n",
    "        predicted_prob_toxic = clf.predict_proba(doses.reshape(-1, 1))[:, 1]\n",
    "        next_dose_idx = np.argmin(np.abs(predicted_prob_toxic - 0.33))\n",
    "\n",
    "    for sample in range(7):\n",
    "        new_data = sim_data(next_dose_idx, true_toxic_probabilities)\n",
    "        data = pd.concat([data, new_data], axis=0, ignore_index=True)\n",
    "        X = data['doses'].values.reshape(-1, 1) # only one feature so needs to be reshaped to a column vector\n",
    "        y = data['toxicity_event']\n",
    "        only_one_class_bool = (y == 0).sum() == len(y)\n",
    "        if only_one_class_bool:\n",
    "            next_dose_idx = 4\n",
    "        elif (y == 1).sum() == len(y):\n",
    "            next_dose_idx = 0\n",
    "        else:\n",
    "            clf = LogisticRegression(solver='lbfgs',random_state=0, warm_start=True).fit(X, y)\n",
    "            predicted_prob_toxic = clf.predict_proba(doses.reshape(-1, 1))[:, 1]\n",
    "            next_dose_idx = np.argmin(np.abs(predicted_prob_toxic - 0.33))\n",
    "    \n",
    "    # intialize the weights to 1\n",
    "    data['sample_weight'] = 1\n",
    "    \n",
    "    for sample in range(7, 11):\n",
    "        # use the model to get the predicted probability of a toxic event given current dose\n",
    "        predict_prob_next_3 = clf.predict_proba(doses[next_dose_idx].reshape(1, -1))[0][1]\n",
    "        # get the expected number of toxicities given the predicted probability\n",
    "        expected_num_toxic = round(np.mean(np.random.binomial(3, p=predict_prob_next_3, size=50_000)))\n",
    "        # simulate the true data\n",
    "        new_data = sim_data(next_dose_idx, true_toxic_probabilities)\n",
    "        true_num_toxic = new_data['toxicity_event'].sum()\n",
    "        if expected_num_toxic == true_num_toxic:\n",
    "            new_data['sample_weight'] = 1 # just guessing the weight here. Tentative. \n",
    "        else:\n",
    "            new_data['sample_weight'] = 1\n",
    "        data = pd.concat([data, new_data], axis=0, ignore_index=True)\n",
    "        X = data['doses'].values.reshape(-1, 1) # only one feature so needs to be reshaped to a column vector\n",
    "        y = data['toxicity_event']\n",
    "        clf = LogisticRegression(solver='lbfgs',random_state=0, warm_start=True).fit(X, y, sample_weight=data['sample_weight'])\n",
    "        predicted_prob_toxic = clf.predict_proba(doses.reshape(-1, 1))[:, 1]\n",
    "        next_dose_idx = np.argmin(np.abs(predicted_prob_toxic - 0.33))        \n",
    "    results.append(next_dose_idx)\n",
    "    final_model.append(clf) # can be used for checking the fitted curve\n",
    "true_label_idx = np.argmin(np.abs(np.array(true_toxic_probabilities) - 0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, counts = np.unique(results, return_counts=True)\n",
    "percent_class_predictions = counts / sum(counts)\n",
    "percent_class_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets visualize what the model is doing when reweighting the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities_reweighted = []\n",
    "for model in final_model:\n",
    "    predictions = model.predict_proba(doses.reshape(-1, 1))[:, 1]\n",
    "    predicted_probabilities_reweighted.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at average over all simulations\n",
    "sns.lineplot(x=doses, y=np.mean(predicted_probabilities_reweighted, axis=0))\n",
    "plt.scatter(x=doses, y=true_toxic_prob_s1, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at average over all simulations\n",
    "sns.lineplot(x=doses, y=np.mean(predicted_probabilities_reweighted, axis=0))\n",
    "plt.scatter(x=doses, y=true_toxic_prob_s1, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[30:35, 'sample_weight'] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_sample_data = data.query(\"doses < 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs',random_state=0, warm_start=True).fit(X, y, sample_weight=data['sample_weight'])\n",
    "clf = LogisticRegression(solver='lbfgs',random_state=0, warm_start=True).fit(reduced_sample_data['doses'].values.reshape(-1, 1), reduced_sample_data['toxicity_event'])\n",
    "clf = LogisticRegression(solver='lbfgs',random_state=0, warm_start=True).fit(data['doses'].values.reshape(-1, 1), data['toxicity_event'], sample_weight=data['sample_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = clf.predict_proba(doses.reshape(-1, 1))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at individual simulations\n",
    "sns.lineplot(x=doses, y=predicted_probabilities_reweighted[-1])\n",
    "sns.lineplot(x=doses, y=new_pred, color='k')\n",
    "plt.scatter(x=doses, y=true_toxic_prob_s1, color='red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
